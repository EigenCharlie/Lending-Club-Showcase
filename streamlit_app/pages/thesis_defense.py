"""Mapa integrado de m√©todos para riesgo de cr√©dito."""

from __future__ import annotations

import sys
from pathlib import Path

_REPO_ROOT = Path(__file__).resolve().parents[2]
if str(_REPO_ROOT) not in sys.path:
    sys.path.insert(0, str(_REPO_ROOT))


import pandas as pd
import plotly.express as px
import streamlit as st

from streamlit_app.components.metric_cards import kpi_row
from streamlit_app.components.narrative import next_page_teaser
from streamlit_app.theme import PLOTLY_TEMPLATE
from streamlit_app.utils import format_number, format_pct, load_json, load_parquet

st.title("üß© Mapa Integrado de M√©todos")
st.caption(
    "S√≠ntesis de c√≥mo se complementan machine learning, estad√≠stica, an√°lisis causal "
    "e investigaci√≥n de operaciones en el pipeline."
)
st.markdown(
    """
Esta p√°gina funciona como puente entre m√≥dulos: no eval√∫a una sola t√©cnica, sino c√≥mo se encadenan para transformar
datos hist√≥ricos en decisiones de riesgo con impacto econ√≥mico y regulatorio. El objetivo es mostrar que el valor del
proyecto no est√° en una m√©trica aislada, sino en la **complementariedad metodol√≥gica** entre predicci√≥n, incertidumbre,
causalidad, optimizaci√≥n y cumplimiento IFRS9.
"""
)

summary = load_json("pipeline_summary")
model_cmp = load_json("model_comparison")
conformal = load_json("conformal_policy_status", directory="models")
governance = load_json("modeva_governance_status", directory="models")

pipeline = summary.get("pipeline", {})
final = model_cmp.get("final_test_metrics", {})
rule = load_parquet("causal_policy_rule_selected").iloc[0]
ifrs9 = load_parquet("ifrs9_scenario_summary")

kpi_row(
    [
        {"label": "AUC ML", "value": f"{final.get('auc_roc', 0):.4f}"},
        {"label": "Cobertura 90%", "value": format_pct(conformal.get("coverage_90", 0))},
        {"label": "C-index RSF", "value": f"{summary.get('survival', {}).get('rsf_concordance', 0):.4f}"},
        {"label": "Valor causal neto", "value": format_number(rule.get("total_net_value", 0), prefix="$")},
        {"label": "Retorno robusto", "value": format_number(pipeline.get("robust_return", 0), prefix="$")},
        {"label": "Gobernanza", "value": "OK" if governance.get("overall_pass", False) else "Revisi√≥n"},
    ],
    n_cols=3,
)

st.subheader("Qu√© aporta cada disciplina")
methods = pd.DataFrame(
    [
        {
            "Disciplina": "Machine Learning",
            "T√©cnica principal": "CatBoost calibrado + SHAP",
            "Pregunta que responde": "¬øQu√© pr√©stamos tienen mayor probabilidad de default?",
            "Artefacto": "model_comparison.json / shap_summary.parquet",
            "Valor para riesgo": "Priorizaci√≥n y explicaci√≥n de riesgo individual",
        },
        {
            "Disciplina": "Estad√≠stica de incertidumbre",
            "T√©cnica principal": "Conformal Mondrian",
            "Pregunta que responde": "¬øCon qu√© banda de confianza estimamos la PD?",
            "Artefacto": "conformal_intervals_mondrian.parquet",
            "Valor para riesgo": "Cobertura emp√≠rica y control de sobreconfianza",
        },
        {
            "Disciplina": "Series + Supervivencia",
            "T√©cnica principal": "Forecasting + KM/Cox/RSF",
            "Pregunta que responde": "¬øC√≥mo evoluciona el riesgo en el tiempo?",
            "Artefacto": "time_series.parquet / lifetime_pd_table.parquet",
            "Valor para riesgo": "Forward-looking y horizonte de provisiones",
        },
        {
            "Disciplina": "Inferencia causal",
            "T√©cnica principal": "CausalForestDML + policy learning",
            "Pregunta que responde": "¬øQu√© acciones cambian realmente el riesgo?",
            "Artefacto": "causal_policy_rule_selected.parquet",
            "Valor para riesgo": "Intervenciones con impacto econ√≥mico estimado",
        },
        {
            "Disciplina": "Investigaci√≥n de operaciones",
            "T√©cnica principal": "Optimizaci√≥n robusta (Pyomo/HiGHS)",
            "Pregunta que responde": "¬øC√≥mo asignar capital bajo incertidumbre?",
            "Artefacto": "portfolio_robustness_frontier.parquet",
            "Valor para riesgo": "Trade-off expl√≠cito retorno vs robustez",
        },
    ]
)
st.dataframe(methods, use_container_width=True, hide_index=True)

st.subheader("Cadena de valor anal√≠tica")
st.markdown(
    """
Para evitar interpretaciones enga√±osas, aqu√≠ no mezclamos en una sola escala n√∫meros de naturaleza distinta
(`AUC` entre 0 y 1 frente a impactos en millones de USD). Se muestran por separado:
1. **Calidad t√©cnica** del sistema (predicci√≥n, cobertura, tiempo-a-evento).
2. **Impacto econ√≥mico/regulatorio** (retorno robusto, valor causal, ECL IFRS9).
"""
)
st.markdown(
    """
La lectura correcta de esta cadena es secuencial y no decorativa. Primero verificamos que el bloque t√©cnico sea confiable:
si el ranking de riesgo no separa bien (`AUC`), si la incertidumbre no cubre lo prometido (`coverage`) o si el horizonte
temporal no discrimina bien (`C-index`), cualquier c√°lculo econ√≥mico posterior queda expuesto a error estructural.
Solo despu√©s tiene sentido leer los impactos en valor neto, asignaci√≥n de capital y provisiones IFRS9.
"""
)

tech_chain = pd.DataFrame(
    [
        {"m√©trica": "AUC OOT", "valor": final.get("auc_roc", 0.0), "bloque": "Predicci√≥n"},
        {"m√©trica": "Cobertura 90%", "valor": conformal.get("coverage_90", 0.0), "bloque": "Incertidumbre"},
        {"m√©trica": "C-index RSF", "valor": summary.get("survival", {}).get("rsf_concordance", 0.0), "bloque": "Horizonte"},
    ]
)
value_chain = pd.DataFrame(
    [
        {"etapa": "Retorno robusto", "valor_usd": pipeline.get("robust_return", 0.0), "tipo": "Impacto econ√≥mico"},
        {"etapa": "Valor causal neto", "valor_usd": float(rule.get("total_net_value", 0.0)), "tipo": "Impacto econ√≥mico"},
        {"etapa": "IFRS9 baseline", "valor_usd": float(ifrs9[ifrs9["scenario"] == "baseline"]["total_ecl"].iloc[0]), "tipo": "Impacto regulatorio"},
        {"etapa": "IFRS9 severe", "valor_usd": float(ifrs9[ifrs9["scenario"] == "severe"]["total_ecl"].iloc[0]), "tipo": "Impacto regulatorio"},
    ]
)

col_a, col_b = st.columns(2)
with col_a:
    fig = px.bar(
        tech_chain,
        x="m√©trica",
        y="valor",
        color="bloque",
        title="Calidad t√©cnica por bloque",
        labels={"m√©trica": "", "valor": "Valor"},
    )
    fig.update_layout(**PLOTLY_TEMPLATE["layout"], height=390, showlegend=True)
    fig.update_yaxes(range=[0, 1], tickformat=".0%")
    st.plotly_chart(fig, use_container_width=True)
    st.caption(
        "Prop√≥sito: validar que cada bloque t√©cnico cumpla su funci√≥n antes de monetizar resultados. "
        "Insight: cuando AUC, cobertura y C-index se mantienen en niveles consistentes, la cadena de decisi√≥n "
        "aguas abajo es m√°s defendible."
    )
with col_b:
    fig = px.bar(
        value_chain,
        x="etapa",
        y="valor_usd",
        color="tipo",
        barmode="group",
        title="Impacto econ√≥mico/regulatorio (USD)",
        labels={"etapa": "", "valor_usd": "USD"},
    )
    fig.update_layout(**PLOTLY_TEMPLATE["layout"], height=390)
    st.plotly_chart(fig, use_container_width=True)
    st.caption(
        "Prop√≥sito: traducir desempe√±o anal√≠tico a impacto econ√≥mico y regulatorio. "
        "Insight: retorno robusto y valor causal muestran creaci√≥n de valor, mientras IFRS9 refleja carga prudencial "
        "bajo escenarios macro."
    )

st.dataframe(
    pd.DataFrame(
        [
            {
                "Elemento": "AUC / Cobertura / C-index",
                "Lectura": "Miden calidad t√©cnica del sistema en separaci√≥n, incertidumbre y horizonte temporal.",
                "Por qu√© importa": "Sin calidad t√©cnica, el impacto econ√≥mico downstream no es confiable.",
            },
            {
                "Elemento": "Retorno robusto y valor causal",
                "Lectura": "Cuantifican creaci√≥n de valor de pol√≠tica bajo incertidumbre y con intervenciones espec√≠ficas.",
                "Por qu√© importa": "Conectan modelado con decisiones rentables y defendibles.",
            },
            {
                "Elemento": "ECL IFRS9 baseline/severe",
                "Lectura": "Miden sensibilidad contable/regulatoria ante escenarios macro.",
                "Por qu√© importa": "Traducen resultados anal√≠ticos en requerimientos de provisi√≥n y capital.",
            },
        ]
    ),
    use_container_width=True,
    hide_index=True,
)
st.markdown(
    """
En conjunto, ambas vistas responden tres preguntas de comit√© de riesgo:
1. ¬øEl sistema t√©cnico es cre√≠ble?
2. ¬øQu√© valor econ√≥mico genera cuando se toma decisi√≥n bajo incertidumbre?
3. ¬øQu√© implicaci√≥n regulatoria deja en provisiones y capital?
Ese puente t√©cnico-negocio es la esencia de esta cadena de valor anal√≠tica.
"""
)

st.subheader("Matriz de complementariedad")
matrix = pd.DataFrame(
    [
        {"M√≥dulo": "Historia de datos", "Alimenta a": "ML / Causal / OR", "Producto": "Segmentaci√≥n y drivers base"},
        {"M√≥dulo": "Modelos PD", "Alimenta a": "Conformal / OR / IFRS9", "Producto": "Probabilidades calibradas"},
        {"M√≥dulo": "Conformal", "Alimenta a": "OR / IFRS9", "Producto": "Intervalos de incertidumbre"},
        {"M√≥dulo": "Series de tiempo", "Alimenta a": "IFRS9", "Producto": "Escenarios forward-looking"},
        {"M√≥dulo": "Supervivencia", "Alimenta a": "IFRS9", "Producto": "Estructura temporal de PD"},
        {"M√≥dulo": "Causalidad", "Alimenta a": "OR / negocio", "Producto": "Reglas de intervenci√≥n"},
        {"M√≥dulo": "Optimizaci√≥n", "Alimenta a": "Comit√© de riesgo", "Producto": "Pol√≠tica de asignaci√≥n"},
        {"M√≥dulo": "Gobernanza", "Alimenta a": "Control interno", "Producto": "Validaci√≥n y trazabilidad"},
    ]
)
st.dataframe(matrix, use_container_width=True, hide_index=True)

st.subheader("Diferenciaci√≥n vs. ecosistema p√∫blico")
st.markdown(
    """
Se analizaron **m√°s de 60 notebooks p√∫blicos** en Kaggle sobre el mismo dataset de Lending Club
(5 versiones del dataset, m√∫ltiples autores). El panorama es claro:
"""
)
diff_data = pd.DataFrame(
    [
        {"T√©cnica": "EDA y visualizaci√≥n", "Kaggle (60+ notebooks)": "Ampliamente cubierto", "Este proyecto": "Cubierto + contexto macro + geograf√≠a"},
        {"T√©cnica": "Clasificaci√≥n binaria (RF, XGBoost, LogReg)", "Kaggle (60+ notebooks)": "Est√°ndar en ~80% de notebooks", "Este proyecto": "CatBoost + calibraci√≥n Platt (ECE=0.0128)"},
        {"T√©cnica": "SHAP / explicabilidad", "Kaggle (60+ notebooks)": "1-2 notebooks en detalle", "Este proyecto": "Cubierto en NB03 + Streamlit"},
        {"T√©cnica": "Validaci√≥n out-of-time", "Kaggle (60+ notebooks)": "Ninguno (todos usan random split)", "Este proyecto": "Split temporal 2007-2017 / 2017 / 2018-2020"},
        {"T√©cnica": "WOE/IV feature engineering", "Kaggle (60+ notebooks)": "Ninguno", "Este proyecto": "OptBinning con supervisi√≥n monot√≥nica"},
        {"T√©cnica": "Calibraci√≥n de probabilidades", "Kaggle (60+ notebooks)": "Ninguno", "Este proyecto": "Platt vs Isotonic vs Venn-Abers"},
        {"T√©cnica": "Conformal prediction", "Kaggle (60+ notebooks)": "Ninguno", "Este proyecto": "MAPIE Mondrian con cobertura garantizada"},
        {"T√©cnica": "Survival analysis", "Kaggle (60+ notebooks)": "Ninguno", "Este proyecto": "Cox PH + RSF para PD lifetime"},
        {"T√©cnica": "Inferencia causal", "Kaggle (60+ notebooks)": "Ninguno", "Este proyecto": "DML + Causal Forest (ATE + CATE)"},
        {"T√©cnica": "Portfolio optimization", "Kaggle (60+ notebooks)": "Ninguno (1 notebook con threshold simple)", "Este proyecto": "Pyomo/HiGHS robusta con uncertainty sets"},
        {"T√©cnica": "IFRS9 / ECL / staging", "Kaggle (60+ notebooks)": "Ninguno", "Este proyecto": "4 escenarios + sensibilidad + conformal SICR"},
        {"T√©cnica": "Predict-then-optimize", "Kaggle (60+ notebooks)": "Ninguno", "Este proyecto": "Pipeline completo PD ‚Üí Conformal ‚Üí Pyomo"},
    ]
)
st.dataframe(diff_data, use_container_width=True, hide_index=True, height=460)
st.info(
    "**Conclusi√≥n:** Las t√©cnicas que definen este proyecto ‚Äî conformal prediction, optimizaci√≥n robusta, "
    "causalidad, survival analysis, IFRS9 y el pipeline predict-then-optimize ‚Äî no aparecen en ning√∫n "
    "notebook p√∫blico de Kaggle sobre este dataset. La contribuci√≥n metodol√≥gica es genuinamente diferenciada."
)

st.markdown(
    """
**Mensaje final del proyecto:**
- No es un conjunto de notebooks aislados: es un sistema anal√≠tico coherente.
- Cada t√©cnica aporta una perspectiva distinta del mismo problema de riesgo.
- La combinaci√≥n mejora explicabilidad, decisi√≥n y gobernabilidad del proceso completo.
"""
)
st.markdown(
    """
Como historia completa, la lectura es esta: partimos de datos heterog√©neos, construimos se√±al predictiva calibrada,
cuantificamos incertidumbre con garant√≠as emp√≠ricas, identificamos palancas causales de intervenci√≥n y finalmente tomamos
decisiones robustas de cartera bajo restricciones reales. La aportaci√≥n del proyecto no es solo "predecir mejor", sino
demostrar c√≥mo integrar t√©cnicas poco combinadas en una misma cadena de valor para riesgo de cr√©dito aplicado.
"""
)

next_page_teaser(
    "Historia de Datos",
    "Volver al inicio del recorrido anal√≠tico y navegar el pipeline completo.",
    "pages/data_story.py",
)
