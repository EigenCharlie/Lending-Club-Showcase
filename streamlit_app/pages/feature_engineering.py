"""Ingenier√≠a de features: transformaci√≥n de variables crudas a se√±ales predictivas."""

from __future__ import annotations

import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import streamlit as st

from streamlit_app.components.audience_toggle import audience_selector
from streamlit_app.components.narrative import narrative_block, next_page_teaser
from streamlit_app.theme import PLOTLY_TEMPLATE
from streamlit_app.utils import (
    get_notebook_image_path,
    load_json,
)

st.title("üîß Ingenier√≠a de Features")
st.caption(
    "De 142 variables crudas a 60 features predictivas: limpieza, transformaci√≥n, "
    "WOE encoding y selecci√≥n por Information Value."
)

audience = audience_selector()

narrative_block(
    audience,
    general="Las variables crudas del dataset necesitan transformaci√≥n antes de alimentar un modelo. "
    "Es como preparar ingredientes antes de cocinar: seleccionar los mejores, limpiarlos y cortarlos "
    "en el formato adecuado.",
    business="La ingenier√≠a de features es la etapa que m√°s impacta el poder predictivo del modelo. "
    "Aqu√≠ se decide qu√© informaci√≥n entra al score, c√≥mo se codifica y qu√© se descarta. "
    "Una mala selecci√≥n de variables puede invalidar todo el pipeline downstream.",
    technical="Pipeline: Raw CSV (142 cols) ‚Üí eliminaci√≥n de leakage, nulls, IDs, constantes (‚Üí110 cols) ‚Üí "
    "feature engineering (ratios, buckets, WOE, flags, interacciones) ‚Üí selecci√≥n por IV ‚Üí "
    "60 features finales (CatBoost). WOE v√≠a OptBinning con supervision monot√≥nica.",
)

# ‚îÄ‚îÄ 1. Pipeline Visual ‚îÄ‚îÄ
st.subheader("1) Pipeline de transformaci√≥n")

pipeline_data = pd.DataFrame([
    {"Etapa": "1. Datos crudos", "Columnas": "142", "Acci√≥n": "CSV original de Kaggle (2.93M filas)", "Raz√≥n": "Punto de partida"},
    {"Etapa": "2. Limpieza (leakage + nulidad + IDs)", "Columnas": "142 ‚Üí 110", "Acci√≥n": "Remover leakage, nulls >80%, IDs, constantes, texto libre", "Raz√≥n": "Variables sin valor predictivo o que generan trampa"},
    {"Etapa": "3. Feature engineering", "Columnas": "110 + 15 creadas", "Acci√≥n": "Ratios, logs, buckets, WOE encoding, flags, interacciones", "Raz√≥n": "Capturar se√±ales no lineales y relaciones"},
    {"Etapa": "4. Reemplazar/eliminar redundantes", "Columnas": "‚àí50 reemplazadas", "Acci√≥n": "sub_grade‚Üígrade_woe, timestamps‚Üífeatures temporales, etc.", "Raz√≥n": "WOE/buckets reemplazan originales"},
    {"Etapa": "5. Selecci√≥n final", "Columnas": "60", "Acci√≥n": "Ranking por IV + importancia SHAP", "Raz√≥n": "Balance poder predictivo vs complejidad"},
])
st.dataframe(pipeline_data, use_container_width=True, hide_index=True)

st.info(
    "**Punto cr√≠tico ‚Äî Data Leakage**: Se removieron 15 variables que solo existen despu√©s de que "
    "el pr√©stamo termina (total_pymnt, recoveries, collection_recovery_fee, etc.). Incluirlas "
    "inflar√≠a artificialmente el AUC pero producir√≠a un modelo in√∫til en producci√≥n."
)

# ‚îÄ‚îÄ 2. Features Creadas ‚îÄ‚îÄ
st.subheader("2) Variables creadas (Feature Engineering)")

narrative_block(
    audience,
    general="Se crearon nuevas variables combinando las originales para capturar patrones que "
    "una sola variable no revela. Por ejemplo, el ratio pr√©stamo/ingreso dice m√°s sobre "
    "el riesgo que el monto del pr√©stamo solo.",
    business="Cada variable creada tiene una justificaci√≥n de negocio: mide carga financiera, "
    "comportamiento crediticio o estabilidad del solicitante. No son transformaciones arbitrarias.",
    technical="Transformaciones: logar√≠tmicas (normalizar distribuciones sesgadas), ratios (capturar "
    "interacciones), bucketing por cuantiles (discretizar continuas), WOE encoding (relaci√≥n "
    "monot√≥nica con target), flags de missing (missingness informativa).",
)

features_created = pd.DataFrame([
    {"Feature": "loan_to_income", "F√≥rmula/M√©todo": "loan_amnt / annual_inc", "Tipo": "Ratio", "Intuici√≥n de riesgo": "Carga del pr√©stamo relativa a capacidad de pago. Ratio alto = mayor riesgo."},
    {"Feature": "revol_utilization", "F√≥rmula/M√©todo": "revol_bal √ó revol_util / 100", "Tipo": "Ratio", "Intuici√≥n de riesgo": "Uso real del cr√©dito revolvente. Alta utilizaci√≥n se√±ala estr√©s financiero."},
    {"Feature": "log_loan_amnt", "F√≥rmula/M√©todo": "log(loan_amnt)", "Tipo": "Log transform", "Intuici√≥n de riesgo": "Normaliza distribuci√≥n sesgada a la derecha. Mejora linealidad."},
    {"Feature": "log_annual_inc", "F√≥rmula/M√©todo": "log(annual_inc)", "Tipo": "Log transform", "Intuici√≥n de riesgo": "Comprime la cola larga de ingresos altos. Estabiliza varianza."},
    {"Feature": "int_rate_bucket", "F√≥rmula/M√©todo": "Quantile binning (deciles)", "Tipo": "Bucket", "Intuici√≥n de riesgo": "Captura relaci√≥n no-lineal entre tasa y default. Cada bucket tiene su tasa de default propia."},
    {"Feature": "dti_bucket", "F√≥rmula/M√©todo": "Quantile binning (deciles)", "Tipo": "Bucket", "Intuici√≥n de riesgo": "Segmenta DTI en bandas de riesgo homog√©neo."},
    {"Feature": "grade_woe", "F√≥rmula/M√©todo": "WOE encoding (OptBinning)", "Tipo": "WOE", "Intuici√≥n de riesgo": "Transforma grade A-G a escala continua ponderada por default rate. Mayor WOE = menor riesgo."},
    {"Feature": "purpose_woe", "F√≥rmula/M√©todo": "WOE encoding (OptBinning)", "Tipo": "WOE", "Intuici√≥n de riesgo": "Codifica prop√≥sito del pr√©stamo seg√∫n su asociaci√≥n hist√≥rica con default."},
    {"Feature": "home_ownership_woe", "F√≥rmula/M√©todo": "WOE encoding (OptBinning)", "Tipo": "WOE", "Intuici√≥n de riesgo": "Situaci√≥n de vivienda como proxy de estabilidad financiera."},
    {"Feature": "emp_length_cat", "F√≥rmula/M√©todo": "Binned ordinal", "Tipo": "Bucket", "Intuici√≥n de riesgo": "Antig√ºedad laboral agrupada como proxy de estabilidad."},
    {"Feature": "log_annual_inc_miss", "F√≥rmula/M√©todo": "Indicador 1/0 de nulo", "Tipo": "Flag", "Intuici√≥n de riesgo": "La ausencia de dato de ingreso puede ser informativa (auto-reporte incompleto)."},
    {"Feature": "dti_miss", "F√≥rmula/M√©todo": "Indicador 1/0 de nulo", "Tipo": "Flag", "Intuici√≥n de riesgo": "DTI nulo puede indicar falta de historial de deuda o dato no verificable."},
    {"Feature": "days_since_delinq_miss", "F√≥rmula/M√©todo": "Indicador 1/0 de nulo", "Tipo": "Flag", "Intuici√≥n de riesgo": "Nulo = nunca hubo morosidad (buen signo). Informativo para el modelo."},
    {"Feature": "int_rate_bucket__grade", "F√≥rmula/M√©todo": "Interacci√≥n bucket √ó grade", "Tipo": "Interacci√≥n", "Intuici√≥n de riesgo": "Captura que el impacto de la tasa depende del grade asignado."},
])
st.dataframe(features_created, use_container_width=True, hide_index=True)

# ‚îÄ‚îÄ 3. IV Ranking ‚îÄ‚îÄ
st.subheader("3) Ranking por Information Value (IV)")

narrative_block(
    audience,
    general="Information Value mide qu√© tan √∫til es cada variable para distinguir entre pr√©stamos "
    "que pagan y los que no. Es como un examen de admisi√≥n para variables: solo las que "
    "aportan informaci√≥n real pasan.",
    business="Las variables con IV bajo (<0.02) se descartan porque no ayudan a predecir default. "
    "Las de IV alto (>0.3) son las m√°s valiosas para el scoring y deben monitorearse activamente.",
    technical="IV = Œ£ (D%‚àíND%) √ó ln(D%/ND%) sobre bins. Rangos: <0.02 d√©bil, 0.02-0.1 √∫til, "
    "0.1-0.3 fuerte, >0.3 muy fuerte. WOE features tienden a IV alto por dise√±o.",
)

iv_data = load_json("feature_importance_iv")
iv_scores = iv_data.get("iv_scores", {})

if iv_scores:
    n_top = st.slider("N√∫mero de features a mostrar", 8, min(30, len(iv_scores)), 20)
    top_iv = dict(list(iv_scores.items())[:n_top])

    iv_df = pd.DataFrame({"feature": list(top_iv.keys()), "iv": list(top_iv.values())})
    iv_df = iv_df.sort_values("iv", ascending=True)

    fig = px.bar(
        iv_df,
        x="iv",
        y="feature",
        orientation="h",
        title=f"Top {n_top} features por Information Value",
        labels={"iv": "Information Value", "feature": ""},
        color="iv",
        color_continuous_scale="YlOrRd",
    )
    # Add IV threshold lines
    for threshold, label, color in [
        (0.02, "D√©bil", "#94A3B8"),
        (0.1, "Fuerte", "#F59E0B"),
        (0.3, "Muy fuerte", "#EF4444"),
    ]:
        fig.add_vline(x=threshold, line_dash="dash", line_color=color, annotation_text=label)

    fig.update_layout(**PLOTLY_TEMPLATE["layout"], height=max(350, n_top * 28), coloraxis_showscale=False)
    st.plotly_chart(fig, use_container_width=True)
    st.caption(
        "L√≠neas verticales: umbrales de IV. <0.02=d√©bil (no predictiva), 0.02-0.1=√∫til, "
        "0.1-0.3=fuerte, >0.3=muy fuerte. Las features WOE dominan el ranking."
    )

    # Feature family summary
    feature_lists = iv_data.get("feature_lists", {})
    st.markdown(
        f"""
**Resumen de familias de features:**
- Num√©ricas: **{len(feature_lists.get('numeric', []))}** variables
- Categ√≥ricas: **{len(feature_lists.get('categorical', []))}** variables
- WOE: **{len(feature_lists.get('woe', []))}** variables
- Flags: **{len(feature_lists.get('flag', []))}** variables
- Interacciones: **{len(feature_lists.get('interaction', []))}** variables
- Total CatBoost: **{len(feature_lists.get('catboost', []))}** features
"""
    )

# ‚îÄ‚îÄ 4. WOE Explained ‚îÄ‚îÄ
st.subheader("4) Weight of Evidence (WOE) explicado")

col_woe1, col_woe2 = st.columns(2)

with col_woe1:
    st.markdown(
        """
**¬øQu√© es WOE?**

Weight of Evidence transforma categor√≠as en valores num√©ricos que reflejan su
relaci√≥n con el default. Para cada categor√≠a (bin):

$$WOE_i = \\ln\\left(\\frac{\\%\\ No\\ Default_i}{\\%\\ Default_i}\\right)$$

- **WOE positivo** ‚Üí categor√≠a con menor proporci√≥n de defaults (bajo riesgo)
- **WOE negativo** ‚Üí categor√≠a con mayor proporci√≥n de defaults (alto riesgo)
- **WOE = 0** ‚Üí proporci√≥n de defaults igual al promedio
"""
    )

with col_woe2:
    st.markdown(
        """
**¬øPor qu√© WOE en credit scoring?**

1. **Interpretabilidad**: Transforma categor√≠as a escala de riesgo monot√≥nica
2. **Manejo de categor√≠as raras**: Agrupa bins con pocos datos
3. **Est√°ndar regulatorio**: Aceptado por supervisores bancarios (EBA, OCC)
4. **Compatibilidad**: Funciona tanto en LogReg como en gradient boosting
5. **OptBinning**: Librer√≠a que optimiza bins respetando monotonicidad
"""
    )

st.info(
    "En este proyecto, WOE se aplica a **grade**, **purpose** y **home_ownership**. "
    "Estas tres features WOE est√°n entre las de mayor IV del modelo, confirmando que "
    "la transformaci√≥n captura informaci√≥n predictiva relevante."
)

# ‚îÄ‚îÄ 5. Variables Eliminadas ‚îÄ‚îÄ
st.subheader("5) Variables eliminadas: anatom√≠a de la limpieza")

st.markdown(
    """
El dataset crudo tiene **142 columnas**. Tras limpieza se retienen **110 columnas** (32 eliminadas
por nulidad, leakage, IDs y constantes). Luego, la ingenier√≠a de features transforma, reemplaza y
selecciona hasta llegar a **60 features finales** para CatBoost.
"""
)

eliminated = pd.DataFrame([
    {"Etapa": "1. Limpieza inicial", "Raz√≥n": "Alta nulidad (>80%)", "Eliminadas": 14, "Ejemplos": "mths_since_last_major_derog, annual_inc_joint, dti_joint, il_util", "Justificaci√≥n": "Datos insuficientes para aprender patrones confiables"},
    {"Etapa": "1. Limpieza inicial", "Raz√≥n": "Data leakage (post-loan)", "Eliminadas": 10, "Ejemplos": "total_pymnt, recoveries, collection_recovery_fee, out_prncp", "Justificaci√≥n": "Solo existen despu√©s de que termina el pr√©stamo ‚Äî usarlas ser√≠a trampa"},
    {"Etapa": "1. Limpieza inicial", "Raz√≥n": "Identificadores", "Eliminadas": 2, "Ejemplos": "id, member_id", "Justificaci√≥n": "√önicos por fila, sin poder predictivo"},
    {"Etapa": "1. Limpieza inicial", "Raz√≥n": "Constantes / quasi-constantes", "Eliminadas": 3, "Ejemplos": "policy_code, pymnt_plan", "Justificaci√≥n": "Un solo valor para todos los pr√©stamos"},
    {"Etapa": "1. Limpieza inicial", "Raz√≥n": "Texto libre no estructurado", "Eliminadas": 3, "Ejemplos": "emp_title, title, desc", "Justificaci√≥n": "Requerir√≠a NLP; reemplazado por purpose y emp_length"},
    {"Etapa": "2. Feature engineering", "Raz√≥n": "Reemplazadas por encoding WOE/bucket", "Eliminadas": 45, "Ejemplos": "sub_grade ‚Üí grade_woe, addr_state, timestamps crudos", "Justificaci√≥n": "Representaci√≥n m√°s eficiente generada"},
    {"Etapa": "2. Feature engineering", "Raz√≥n": "Duplicadas / redundantes", "Eliminadas": 5, "Ejemplos": "funded_amnt (‚âàloan_amnt), funded_amnt_inv", "Justificaci√≥n": "Informaci√≥n ya capturada por otra variable"},
])
st.dataframe(eliminated, use_container_width=True, hide_index=True)

st.warning(
    "**Resultado neto: 142 columnas originales ‚Üí 110 tras limpieza ‚Üí 60 features finales** "
    "(con +15 variables creadas y selecci√≥n por IV/SHAP). "
    "La limpieza rigurosa es la primera l√≠nea de defensa contra modelos sobreajustados o con leakage."
)

# ‚îÄ‚îÄ 6. Notebook Images ‚îÄ‚îÄ
st.subheader("6) Evidencia visual del Notebook 02")

col_img1, col_img2 = st.columns(2)
with col_img1:
    img = get_notebook_image_path("02_feature_engineering", "cell_017_out_00.png")
    if img.exists():
        st.image(str(img), caption="WOE binning: transformaci√≥n monot√≥nica supervisada.", use_container_width=True)
with col_img2:
    img = get_notebook_image_path("02_feature_engineering", "cell_018_out_00.png")
    if img.exists():
        st.image(str(img), caption="IV ranking: selecci√≥n de features por poder predictivo.", use_container_width=True)

# ‚îÄ‚îÄ Closing ‚îÄ‚îÄ
st.markdown(
    """
**Conexi√≥n con el pipeline:** Las 60 features finales alimentan el modelo CatBoost (NB03),
que produce la PD calibrada. A su vez, esa PD entra en el conformal prediction (NB04) para
generar intervalos de incertidumbre, que luego informan la optimizaci√≥n de portafolio (NB08)
y las provisiones IFRS9 (NB09). **Sin features bien dise√±adas, toda la cadena downstream
hereda ruido y sesgo.**
"""
)

next_page_teaser(
    "Historia de Datos",
    "Explora las distribuciones del dataset y los patrones de riesgo que motivaron esta ingenier√≠a de variables.",
    "pages/data_story.py",
)
