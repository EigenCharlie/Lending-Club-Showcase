"""Glosario y fundamentos: tÃ©rminos, tÃ©cnicas y fÃ³rmulas clave del proyecto."""

from __future__ import annotations

import pandas as pd
import streamlit as st

from streamlit_app.components.narrative import next_page_teaser
from streamlit_app.utils import load_json

st.title("ğŸ“– Glosario y Fundamentos")
st.caption(
    "Referencia rÃ¡pida de todos los conceptos, mÃ©tricas, tÃ©cnicas y fÃ³rmulas "
    "utilizados en este proyecto de riesgo de crÃ©dito end-to-end."
)
st.markdown(
    """
Esta pÃ¡gina funciona como diccionario de consulta. Antes de explorar los resultados analÃ­ticos,
aquÃ­ puedes familiarizarte con los tÃ©rminos financieros, regulatorios, de machine learning y
optimizaciÃ³n que aparecen en todo el recorrido. Cada tÃ©rmino incluye una definiciÃ³n accesible
y su conexiÃ³n con el proyecto.
"""
)

# â”€â”€ Glossary Data â”€â”€
comparison = load_json("model_comparison")
final_metrics = comparison.get("final_test_metrics", {})
policy = load_json("conformal_policy_status", directory="models")
pipeline_summary = load_json("pipeline_summary")
pipeline_metrics = pipeline_summary.get("pipeline", {})
survival_metrics = pipeline_summary.get("survival", {})
ifrs9_baseline = float(pipeline_metrics.get("ecl_expected", 0.0))
ifrs9_severe = float(pipeline_metrics.get("ecl_conservative", 0.0))
ifrs9_uplift = (ifrs9_severe / ifrs9_baseline - 1.0) if ifrs9_baseline else 0.0
nonrobust_return = float(pipeline_metrics.get("nonrobust_return", 0.0))
price_of_robustness = float(pipeline_metrics.get("price_of_robustness", 0.0))
por_pct = (price_of_robustness / (abs(nonrobust_return) + 1e-6) * 100.0) if nonrobust_return else 0.0

GLOSSARY = [
    # Financial terms
    {"termino": "PD", "categoria": "Financiero", "definicion": "Probability of Default. Probabilidad de que un prÃ©stamo entre en incumplimiento. Es la salida principal del modelo CatBoost calibrado.", "en_proyecto": f"Modelo PD con AUC={final_metrics.get('auc_roc', 0):.4f}, calibrado con Platt Sigmoid (ECE={final_metrics.get('ece', 0):.4f})."},
    {"termino": "LGD", "categoria": "Financiero", "definicion": "Loss Given Default. Porcentaje del monto expuesto que se pierde cuando ocurre un default. Complemento de la tasa de recuperaciÃ³n.", "en_proyecto": "Modelado sobre prÃ©stamos en default (~88% nulls esperados en no-defaults)."},
    {"termino": "EAD", "categoria": "Financiero", "definicion": "Exposure at Default. Monto expuesto al momento del incumplimiento. Para prÃ©stamos amortizables, es el saldo pendiente.", "en_proyecto": "Dataset especializado ead_dataset.parquet solo con defaults."},
    {"termino": "ECL", "categoria": "Financiero", "definicion": "Expected Credit Loss. PÃ©rdida esperada = PD Ã— LGD Ã— EAD Ã— Factor de descuento. MÃ©trica central de IFRS9.", "en_proyecto": f"ECL baseline ${ifrs9_baseline / 1e6:,.1f}M, escenario severo ${ifrs9_severe / 1e9:,.3f}B ({ifrs9_uplift:+.2%})."},
    {"termino": "DTI", "categoria": "Financiero", "definicion": "Debt-to-Income ratio. Pagos mensuales de deuda divididos entre ingreso mensual. Mediana en el dataset: ~15.", "en_proyecto": "Feature clave del modelo PD. DTI alto (>30) seÃ±ala sobreendeudamiento."},
    {"termino": "NPL", "categoria": "Financiero", "definicion": "Non-Performing Loan. PrÃ©stamo con pagos vencidos >90 dÃ­as o en reestructuraciÃ³n. Equivale a Stage 3 en IFRS9.", "en_proyecto": "PrÃ©stamos Charged Off + Default + Late 31-120 en el dataset."},
    {"termino": "SICR", "categoria": "Financiero", "definicion": "Significant Increase in Credit Risk. Evento que dispara la migraciÃ³n de Stage 1 a Stage 2 en IFRS9.", "en_proyecto": "InnovaciÃ³n: ancho del intervalo conformal (PD_high - PD_point) como seÃ±al adicional de SICR."},
    {"termino": "Write-off", "categoria": "Financiero", "definicion": "Castigo contable: reconocimiento formal de que un prÃ©stamo es irrecuperable. Genera pÃ©rdida directa en resultados.", "en_proyecto": "Estado 'Charged Off' en el dataset de Lending Club."},
    {"termino": "Spread", "categoria": "Financiero", "definicion": "Diferencia entre la tasa cobrada al prestatario y el costo de fondeo. Representa el margen bruto del prÃ©stamo.", "en_proyecto": "int_rate del dataset menos costo de fondeo estimado."},
    {"termino": "Grade", "categoria": "Financiero", "definicion": "CalificaciÃ³n de riesgo de Lending Club (A-G). Grade A default ~2%, Grade G ~37%. Variable de mayor poder predictivo.", "en_proyecto": "Usada en Mondrian conformal para intervalos por grupo y en segmentaciÃ³n IFRS9."},
    # Regulatory terms
    {"termino": "IFRS 9", "categoria": "Regulatorio", "definicion": "International Financial Reporting Standard 9. Norma contable que requiere provisionar pÃ©rdidas esperadas (no solo incurridas). Vigente desde enero 2018.", "en_proyecto": "PÃ¡gina completa de provisiones IFRS9 con 4 escenarios y anÃ¡lisis de sensibilidad."},
    {"termino": "Basilea III", "categoria": "Regulatorio", "definicion": "Marco regulatorio bancario que define requerimientos mÃ­nimos de capital. Los bancos deben mantener capital suficiente para absorber pÃ©rdidas inesperadas.", "en_proyecto": "IFRS9 determina provisiones (pÃ©rdida esperada); Basilea III determina capital (pÃ©rdida inesperada)."},
    {"termino": "Stage 1", "categoria": "Regulatorio", "definicion": "PrÃ©stamos sin deterioro significativo. Se provisiona ECL a 12 meses (PD 12m Ã— LGD Ã— EAD).", "en_proyecto": "MayorÃ­a del portafolio. PD a 12 meses del modelo CatBoost."},
    {"termino": "Stage 2", "categoria": "Regulatorio", "definicion": "PrÃ©stamos con incremento significativo de riesgo (SICR). Se provisiona ECL lifetime (PD lifetime Ã— LGD Ã— EAD).", "en_proyecto": "MigraciÃ³n Stage 1â†’2 analizada con conformal width como seÃ±al SICR."},
    {"termino": "Stage 3", "categoria": "Regulatorio", "definicion": "PrÃ©stamos deteriorados (default, 90+ DPD). PD ~ 1.0, se provisiona pÃ©rdida total esperada.", "en_proyecto": "PrÃ©stamos en Charged Off/Default del dataset."},
    {"termino": "Stress Test", "categoria": "Regulatorio", "definicion": "Ejercicio regulatorio que evalÃºa resiliencia de un portafolio bajo escenarios macroeconÃ³micos adversos.", "en_proyecto": f"4 escenarios IFRS9 (baseline, mild, adverse, severe) con uplift severo actual {ifrs9_uplift:+.2%}."},
    # ML terms
    {"termino": "AUC", "categoria": "Machine Learning", "definicion": "Area Under the ROC Curve. Mide la capacidad del modelo para separar defaults de no-defaults. 0.5=aleatorio, 1.0=perfecto. En banca, AUC >0.70 se considera aceptable.", "en_proyecto": f"CatBoost calibrado: AUC={final_metrics.get('auc_roc', 0):.4f} en test out-of-time."},
    {"termino": "Gini", "categoria": "Machine Learning", "definicion": "Coeficiente Gini = 2Ã—AUC - 1. Escala de 0 (sin poder) a 1 (perfecto). MÃ©trica estÃ¡ndar en credit scoring bancario.", "en_proyecto": f"Gini={final_metrics.get('gini', 0):.4f}, consistente con modelos de crÃ©dito al consumo."},
    {"termino": "KS", "categoria": "Machine Learning", "definicion": "Kolmogorov-Smirnov statistic. MÃ¡xima separaciÃ³n entre distribuciones acumuladas de buenos y malos. KS >0.30 es buen poder discriminante.", "en_proyecto": f"KS={final_metrics.get('ks_statistic', 0):.4f} en test OOT."},
    {"termino": "Brier Score", "categoria": "Machine Learning", "definicion": "Error cuadrÃ¡tico medio de las probabilidades predichas vs outcomes reales. Menor es mejor. Combina discriminaciÃ³n y calibraciÃ³n.", "en_proyecto": f"Brier={final_metrics.get('brier_score', 0):.4f} post-calibraciÃ³n."},
    {"termino": "ECE", "categoria": "Machine Learning", "definicion": "Expected Calibration Error. Mide quÃ© tan bien las probabilidades predichas reflejan las frecuencias reales de default. ECE=0 es calibraciÃ³n perfecta.", "en_proyecto": f"ECE={final_metrics.get('ece', 0):.4f} con Platt Sigmoid (seleccionado sobre Isotonic)."},
    {"termino": "SHAP", "categoria": "Machine Learning", "definicion": "SHapley Additive exPlanations. MÃ©todo de teorÃ­a de juegos que atribuye la contribuciÃ³n de cada variable a cada predicciÃ³n individual.", "en_proyecto": "Top drivers: int_rate, grade, term, loan_to_income, revol_util."},
    {"termino": "CatBoost", "categoria": "Machine Learning", "definicion": "Algoritmo de gradient boosting que maneja variables categÃ³ricas nativamente y es robusto a overfitting. Desarrollado por Yandex. Dominante en competencias de datos tabulares.", "en_proyecto": "Modelo final: CatBoost tuneado con Optuna (1000+ trials) + calibraciÃ³n Platt."},
    {"termino": "Gradient Boosting", "categoria": "Machine Learning", "definicion": "TÃ©cnica de ensamble que construye secuencialmente Ã¡rboles de decisiÃ³n, donde cada nuevo Ã¡rbol corrige los errores del anterior.", "en_proyecto": "CatBoost, XGBoost y LightGBM son variantes de gradient boosting."},
    {"termino": "CalibraciÃ³n", "categoria": "Machine Learning", "definicion": "Ajuste post-entrenamiento para que las probabilidades predichas sean consistentes con las frecuencias observadas. Si predice PD=10%, ~10% deben hacer default.", "en_proyecto": "Platt Sigmoid seleccionada (ECE=0.0128) sobre Isotonic."},
    {"termino": "Cross-validation", "categoria": "Machine Learning", "definicion": "TÃ©cnica de evaluaciÃ³n que divide datos en K subconjuntos para entrenar y validar el modelo K veces, reduciendo sesgo de evaluaciÃ³n.", "en_proyecto": "No usada para split final (se usa OOT temporal), sÃ­ para Optuna."},
    {"termino": "WOE", "categoria": "Machine Learning", "definicion": "Weight of Evidence. TransformaciÃ³n de variables categÃ³ricas/binneadas que captura la relaciÃ³n monotÃ³nica con el default. EstÃ¡ndar en credit scoring.", "en_proyecto": "Aplicado a grade, purpose, home_ownership via OptBinning."},
    {"termino": "IV", "categoria": "Machine Learning", "definicion": "Information Value. Mide el poder predictivo global de una variable. IV <0.02 dÃ©bil, 0.02-0.1 Ãºtil, 0.1-0.3 fuerte, >0.3 muy fuerte.", "en_proyecto": "Usado para ranking y selecciÃ³n de features en NB02."},
    # Uncertainty terms
    {"termino": "Conformal Prediction", "categoria": "Incertidumbre", "definicion": "Marco estadÃ­stico que produce intervalos de predicciÃ³n con garantÃ­a de cobertura finita sin asumir distribuciÃ³n paramÃ©trica. Solo requiere intercambiabilidad de datos.", "en_proyecto": f"MAPIE 1.3.0 SplitConformalRegressor. Cobertura 90%={policy.get('coverage_90', 0):.4f}, 95%={policy.get('coverage_95', 0):.4f}."},
    {"termino": "Coverage (Cobertura)", "categoria": "Incertidumbre", "definicion": "ProporciÃ³n de valores reales que caen dentro del intervalo predicho. Cobertura 90% = 90% de los valores reales estÃ¡n en [PD_low, PD_high].", "en_proyecto": f"90%: {policy.get('coverage_90', 0):.4f}, 95%: {policy.get('coverage_95', 0):.4f}, checks {int(policy.get('checks_passed', 0))}/{int(policy.get('checks_total', 0))}."},
    {"termino": "Mondrian CP", "categoria": "Incertidumbre", "definicion": "Variante de conformal prediction que calcula intervalos por grupo (e.g., por grade), garantizando cobertura condicional por segmento.", "en_proyecto": f"Intervalos por grade. Min cobertura grupo: {policy.get('min_group_coverage_90', 0):.4f} (meta â‰¥0.88)."},
    {"termino": "Interval Width", "categoria": "Incertidumbre", "definicion": "Ancho del intervalo conformal (PD_high - PD_low). Intervalos mÃ¡s estrechos son mÃ¡s informativos pero con mismo nivel de cobertura.", "en_proyecto": f"Ancho promedio 90%: {policy.get('avg_width_90', 0):.4f} (meta <0.80). Usado como seÃ±al SICR."},
    {"termino": "Split Conformal", "categoria": "Incertidumbre", "definicion": "MÃ©todo que usa un conjunto de calibraciÃ³n separado para calcular residuos conformales. MÃ¡s eficiente computacionalmente que full conformal.", "en_proyecto": "SplitConformalRegressor con calibration set temporal separado."},
    # Causal terms
    {"termino": "ATE", "categoria": "Causal", "definicion": "Average Treatment Effect. Efecto promedio de una intervenciÃ³n sobre toda la poblaciÃ³n. Responde: Â¿cuÃ¡nto cambia Y si aplicamos tratamiento T?", "en_proyecto": "+1pp en tasa de interÃ©s â†’ +0.787pp en probabilidad de default."},
    {"termino": "CATE", "categoria": "Causal", "definicion": "Conditional Average Treatment Effect. Efecto causal que varÃ­a por subgrupo/individuo. Permite intervenciones personalizadas.", "en_proyecto": "DistribuciÃ³n amplia de CATE justifica polÃ­tica diferenciada por segmento."},
    {"termino": "DML", "categoria": "Causal", "definicion": "Double/Debiased Machine Learning. MÃ©todo de Chernozhukov et al. (2018) que usa ML para controlar confounders y estimar efectos causales sin sesgo.", "en_proyecto": "EconML LinearDML para estimaciÃ³n robusta del efecto tasa â†’ default."},
    {"termino": "Causal Forest", "categoria": "Causal", "definicion": "ExtensiÃ³n de Random Forest para estimar efectos de tratamiento heterogÃ©neos (CATE). Basado en Athey & Wager (2019).", "en_proyecto": "Modelo de 337MB entrenado para CATE heterogÃ©neo por segmento."},
    {"termino": "Counterfactual", "categoria": "Causal", "definicion": "Escenario hipotÃ©tico: Â¿quÃ© hubiera pasado si hubiÃ©ramos aplicado una intervenciÃ³n diferente? Base del anÃ¡lisis causal.", "en_proyecto": "SimulaciÃ³n contrafactual de polÃ­ticas de intervenciÃ³n por regla."},
    # OR terms
    {"termino": "OptimizaciÃ³n Robusta", "categoria": "Operations Research", "definicion": "Enfoque de optimizaciÃ³n que incorpora incertidumbre en los parÃ¡metros del modelo. En vez de optimizar para el caso esperado, protege contra el peor caso plausible.", "en_proyecto": "PD_high (conformal) como peor caso -> Pyomo/HiGHS resuelve asignaciÃ³n robusta."},
    {"termino": "Uncertainty Set", "categoria": "Operations Research", "definicion": "Conjunto de valores posibles para parÃ¡metros inciertos. En optimizaciÃ³n robusta, el modelo se protege contra todos los escenarios dentro del conjunto.", "en_proyecto": "[PD_low, PD_high] del conformal define el uncertainty set por prÃ©stamo."},
    {"termino": "Price of Robustness", "categoria": "Operations Research", "definicion": "Diferencia en retorno esperado entre la soluciÃ³n Ã³ptima sin incertidumbre y la robusta. Cuantifica el costo de proteger el downside.", "en_proyecto": f"{por_pct:.2f}% de reducciÃ³n de retorno @ tolerancia 0.10 en snapshot actual. Es el 'costo del seguro'."},
    {"termino": "Efficient Frontier", "categoria": "Operations Research", "definicion": "Curva que muestra las mejores combinaciones posibles de riesgo y retorno. No se puede mejorar retorno sin asumir mÃ¡s riesgo.", "en_proyecto": "Frontera eficiente robusta vs no-robusta comparada en la pÃ¡gina de portafolio."},
]

# â”€â”€ Search & Filter â”€â”€
st.subheader("Buscar tÃ©rminos")
col_search, col_cat = st.columns([2, 1])
with col_search:
    search = st.text_input("Buscar por nombre o descripciÃ³n", placeholder="Ej: conformal, PD, IFRS...")
with col_cat:
    categories = sorted({g["categoria"] for g in GLOSSARY})
    selected_cat = st.selectbox("Filtrar por categorÃ­a", ["Todas"] + categories)

filtered = GLOSSARY
if search:
    search_lower = search.lower()
    filtered = [
        g for g in filtered
        if search_lower in g["termino"].lower()
        or search_lower in g["definicion"].lower()
        or search_lower in g["en_proyecto"].lower()
    ]
if selected_cat != "Todas":
    filtered = [g for g in filtered if g["categoria"] == selected_cat]

st.markdown(f"**{len(filtered)}** tÃ©rminos encontrados")

df_glossary = pd.DataFrame(filtered)
if not df_glossary.empty:
    df_display = df_glossary.rename(columns={
        "termino": "TÃ©rmino",
        "categoria": "CategorÃ­a",
        "definicion": "DefiniciÃ³n",
        "en_proyecto": "En este proyecto",
    })
    st.dataframe(df_display, use_container_width=True, hide_index=True, height=500)

# â”€â”€ Industry Usage â”€â”€
st.subheader("TÃ©cnicas y su uso en la industria")
st.markdown(
    """
Las tÃ©cnicas empleadas en este proyecto no son experimentales: son herramientas utilizadas
activamente en bancos, fintechs y aseguradoras de primer nivel a nivel mundial.
"""
)

industry_data = [
    {"TÃ©cnica": "CatBoost / XGBoost / LightGBM", "Uso en la industria": "Credit scoring en >70% de instituciones financieras digitales. Dominantes en competencias Kaggle de datos tabulares. Adoptados por JPMorgan, Capital One, Nubank, Mercado Libre.", "En este proyecto": "Modelo PD principal (CatBoost tuneado + Platt)"},
    {"TÃ©cnica": "WOE / IV (Weight of Evidence)", "Uso en la industria": "EstÃ¡ndar de facto en credit scoring bancario desde los aÃ±os 90. Requerido por algunos reguladores para scorecard interpretable.", "En este proyecto": "Feature engineering: grade_woe, purpose_woe, home_ownership_woe"},
    {"TÃ©cnica": "SHAP (Explicabilidad)", "Uso en la industria": "EstÃ¡ndar de explicabilidad ML en banca (requerido por EBA, OCC). Usado para explicar decisiones individuales de crÃ©dito.", "En este proyecto": "Top 20 features con SHAP, dependence plots"},
    {"TÃ©cnica": "Conformal Prediction", "Uso en la industria": "Adoptado en farmacÃ©utica (AstraZeneca), manufactura (Volvo), fintech (cuantificaciÃ³n de incertidumbre en modelos de pricing y riesgo). Crecimiento exponencial desde 2020.", "En este proyecto": "MAPIE Mondrian: intervalos PD con cobertura garantizada por grade"},
    {"TÃ©cnica": "Inferencia Causal (DML/CATE)", "Uso en la industria": "Pricing dinÃ¡mico en Uber/Lyft, campaÃ±as de retenciÃ³n en telecoms, anÃ¡lisis de impacto de polÃ­ticas en banca central (BIS, Fed).", "En este proyecto": "Efecto tasaâ†’default, polÃ­ticas de intervenciÃ³n por segmento"},
    {"TÃ©cnica": "Survival Analysis", "Uso en la industria": "EstimaciÃ³n de lifetime PD para IFRS9 Stage 2 en todos los bancos bajo IFRS. Modelos de churn en telecoms y seguros.", "En este proyecto": f"Cox PH (C={survival_metrics.get('cox_concordance', 0):.4f}) y RSF (C={survival_metrics.get('rsf_concordance', 0):.4f}) para PD lifetime por grade"},
    {"TÃ©cnica": "OptimizaciÃ³n Robusta (Pyomo)", "Uso en la industria": "AsignaciÃ³n de capital en fondos de inversiÃ³n, planificaciÃ³n de supply chain (Amazon, Walmart), gestiÃ³n de portafolio en asset management.", "En este proyecto": "AsignaciÃ³n de prÃ©stamos con uncertainty sets conformales + HiGHS solver"},
    {"TÃ©cnica": "IFRS9 / ECL Modeling", "Uso en la industria": "Obligatorio para todas las instituciones financieras bajo IFRS (>140 paÃ­ses). Cada banco tiene modelos internos de ECL por stage.", "En este proyecto": "4 escenarios, sensibilidad PDÃ—LGD, staging con conformal width"},
    {"TÃ©cnica": "dbt + DuckDB", "Uso en la industria": "dbt: estÃ¡ndar de transformaciÃ³n de datos en startups y empresas data-driven (Spotify, GitLab). DuckDB: anÃ¡lisis local sin servidor (reemplaza SQLite para analÃ­tica).", "En este proyecto": "19 modelos dbt sobre DuckDB local con linaje verificable"},
]
st.dataframe(pd.DataFrame(industry_data), use_container_width=True, hide_index=True)

# â”€â”€ Key Formulas â”€â”€
st.subheader("FÃ³rmulas clave")

col_f1, col_f2 = st.columns(2)

with col_f1:
    st.markdown("**Expected Credit Loss (ECL)**")
    st.latex(r"ECL = PD \times LGD \times EAD \times DF")
    st.caption("Donde DF = factor de descuento. PD a 12 meses (Stage 1) o lifetime (Stage 2).")

    st.markdown("**Coeficiente Gini**")
    st.latex(r"Gini = 2 \times AUC - 1")
    st.caption("Escala: 0 (sin poder discriminante) a 1 (discriminaciÃ³n perfecta).")

    st.markdown("**Brier Score**")
    st.latex(r"Brier = \frac{1}{N}\sum_{i=1}^{N}(p_i - y_i)^2")
    st.caption("Error cuadrÃ¡tico medio de probabilidades. Menor es mejor.")

with col_f2:
    st.markdown("**Cobertura Conformal**")
    st.latex(r"Coverage = \frac{1}{N}\sum_{i=1}^{N}\mathbb{1}[y_i \in C(x_i)]")
    st.caption("ProporciÃ³n de valores reales dentro del intervalo predicho. Meta: â‰¥90% y â‰¥95%.")

    st.markdown("**Price of Robustness**")
    st.latex(r"PoR = \frac{R_{nominal} - R_{robust}}{R_{nominal}} \times 100\%")
    st.caption("Porcentaje de retorno sacrificado por protecciÃ³n contra incertidumbre.")

    st.markdown("**Information Value (IV)**")
    st.latex(r"IV = \sum_{i=1}^{B}(D_i\% - ND_i\%) \times \ln\left(\frac{D_i\%}{ND_i\%}\right)")
    st.caption("Poder predictivo global de una variable. >0.3 = muy fuerte.")

# â”€â”€ Reading Guide â”€â”€
st.subheader("GuÃ­a de lectura del dashboard")
st.markdown(
    """
| Orden | SecciÃ³n | PÃ¡gina | Pregunta que responde |
|:-----:|---------|--------|-----------------------|
| 1 | Inicio | ğŸ  Resumen Ejecutivo | Â¿QuÃ© problema resolvemos y con quÃ© resultados? |
| 2 | Inicio | ğŸ“– Glosario y Fundamentos (esta pÃ¡gina) | Â¿QuÃ© significa cada tÃ©rmino y tÃ©cnica? |
| 3 | Recorrido E2E | ğŸ§­ VisiÃ³n End-to-End | Â¿CuÃ¡l es la narrativa completa del proyecto? |
| 4 | Recorrido E2E | ğŸ—‚ï¸ Arquitectura y Linaje de Datos | Â¿CÃ³mo fluyen los datos a travÃ©s del sistema? |
| 5 | Recorrido E2E | ğŸ§© Mapa Integrado de MÃ©todos | Â¿CÃ³mo se conectan las tÃ©cnicas entre sÃ­? |
| 6 | Recorrido E2E | ğŸ“š Atlas de Evidencia | Â¿DÃ³nde estÃ¡ la evidencia de cada notebook? |
| 7 | AnalÃ­tica | ğŸ”§ IngenierÃ­a de Features | Â¿CÃ³mo se transformaron las variables para el modelo? |
| 8 | AnalÃ­tica | ğŸ“Š Historia de Datos | Â¿QuÃ© contiene el dataset y quÃ© patrones existen? |
| 9 | AnalÃ­tica | ğŸ”¬ Laboratorio de Modelos | Â¿QuÃ© modelo se eligiÃ³ y por quÃ©? |
| 10 | AnalÃ­tica | ğŸ“ CuantificaciÃ³n de Incertidumbre | Â¿CÃ³mo cuantificamos la incertidumbre de las predicciones? |
| 11 | AnalÃ­tica | ğŸ“ˆ Panorama Temporal | Â¿CÃ³mo evolucionan los defaults en el tiempo? |
| 12 | AnalÃ­tica | â³ AnÃ¡lisis de Supervivencia | Â¿CuÃ¡ndo ocurren los defaults? |
| 13 | AnalÃ­tica | ğŸ§¬ Inteligencia Causal | Â¿QuÃ© intervenciones pueden reducir el riesgo? |
| 14 | Decisiones | ğŸ’¼ Optimizador de Portafolio | Â¿CÃ³mo asignar capital bajo incertidumbre? |
| 15 | Decisiones | ğŸ¦ Provisiones IFRS9 | Â¿CuÃ¡nto provisionar bajo diferentes escenarios? |
| 16 | Gobernanza | ğŸ›¡ï¸ Gobernanza del Modelo | Â¿Es el modelo confiable y justo? |
| 17 | ExploraciÃ³n | ğŸ’¬ Chat con Datos | ExploraciÃ³n libre por SQL |
"""
)

next_page_teaser(
    "Historia de Datos",
    "Explora el dataset: distribuciones, patrones de riesgo y dinÃ¡mica temporal de 1.35M prÃ©stamos.",
    "pages/data_story.py",
)
