"""Inteligencia causal para polÃ­ticas de riesgo de crÃ©dito."""

from __future__ import annotations

import sys
from pathlib import Path

_REPO_ROOT = Path(__file__).resolve().parents[2]
if str(_REPO_ROOT) not in sys.path:
    sys.path.insert(0, str(_REPO_ROOT))


import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import streamlit as st

from streamlit_app.components.metric_cards import kpi_row
from streamlit_app.components.narrative import next_page_teaser
from streamlit_app.theme import PLOTLY_TEMPLATE
from streamlit_app.utils import get_notebook_image_path, load_parquet

st.title("ğŸ§¬ Inteligencia Causal")
st.caption(
    "EstimaciÃ³n de efectos causales heterogÃ©neos para orientar polÃ­ticas de precio "
    "y acciones de mitigaciÃ³n de riesgo."
)

with st.expander("Â¿Por quÃ© no basta con correlaciÃ³n? â€” La trampa del scoring tradicional"):
    st.markdown(
        """
### El problema

En el dataset, los prÃ©stamos con **tasas altas tienen mÃ¡s defaults**. Pero, Â¿subir la tasa
*causa* mÃ¡s defaults? Â¿O simplemente le cobramos mÃ¡s a quienes ya eran riesgosos?

**CorrelaciÃ³n**: "Los prÃ©stamos con tasa >20% tienen 24% de default"
**Causalidad**: "Si subimos la tasa 1pp a un cliente, su probabilidad de default sube +0.787pp"

Son preguntas fundamentalmente distintas. La primera describe el pasado; la segunda
permite diseÃ±ar intervenciones futuras.

### Â¿DÃ³nde se usa inferencia causal en la industria?

| Industria | AplicaciÃ³n |
|-----------|------------|
| **Banca** | Pricing dinÃ¡mico: Â¿cuÃ¡nto puedo subir la tasa sin aumentar defaults? |
| **Telecoms** | CampaÃ±as de retenciÃ³n: Â¿a quiÃ©n le funciona el descuento? |
| **RegulaciÃ³n** | Stress testing: Â¿quÃ© pasa si sube la tasa de referencia? |
| **Seguros** | Efecto de franquicias en reclamaciones |
| **Tech** | A/B testing causal (Uber, Lyft, Netflix) |

### Resultado clave del proyecto

> **+1 punto porcentual en tasa de interÃ©s â†’ +0.787pp en probabilidad de default**

Esto tiene implicaciÃ³n econÃ³mica directa: por cada punto de tasa que subes,
pierdes ~0.8% mÃ¡s de prÃ©stamos al default. La polÃ­tica Ã³ptima seleccionada
(regla `high_plus_medium_positive`) genera un valor neto de **$5.857M** en
pÃ©rdidas evitadas, enfocando intervenciones donde el efecto causal es mayor.
"""
    )

st.markdown(
    """
La capa causal aborda una limitaciÃ³n frecuente en analÃ­tica de crÃ©dito: confundir correlaciÃ³n con intervenciÃ³n Ãºtil.
Que una variable estÃ© asociada a mÃ¡s default no implica que mover esa variable cambie el resultado en la misma magnitud.
Por eso se combina diseÃ±o causal (DoWhy) con estimaciÃ³n heterogÃ©nea (EconML), buscando reglas que sean simultÃ¡neamente
plausibles desde identificaciÃ³n y rentables desde impacto econÃ³mico. En el flujo del proyecto, causalidad no reemplaza
al score PD: lo complementa para decidir **dÃ³nde actuar** y no solo **a quiÃ©n clasificar**.
"""
)
st.markdown(
    """
### QuÃ© tÃ©cnica causal se estÃ¡ usando y cÃ³mo leerla
- **ATE** (Average Treatment Effect): efecto promedio de mover una palanca (ej. tasa) sobre default.
- **CATE** (Conditional ATE): ese efecto, pero condicionado por perfil de cliente/segmento.
- **DoWhy** aporta el marco de identificaciÃ³n causal (supuestos, DAG y refutaciÃ³n conceptual).
- **EconML (DML/Causal Forest)** estima efectos heterogÃ©neos con flexibilidad no lineal en tabular.

InterpretaciÃ³n en este proyecto:
- `CATE > 0`: aumentar tasa empeora default (conviene bajar o no subir en ese segmento).
- `CATE < 0`: subir tasa no incrementa default o incluso puede asociarse a mejor selecciÃ³n.
- Una polÃ­tica causal Ãºtil combina magnitud de efecto con restricciÃ³n econÃ³mica (`net_value`).
"""
)
st.markdown(
    """
### Supuestos y lÃ­mites que sÃ­ declaramos
Para interpretar estos efectos como causales, se asumen condiciones estÃ¡ndar de inferencia observacional:
- **Ignorabilidad condicional**: tras controlar covariables relevantes, la asignaciÃ³n de tratamiento es as-if aleatoria.
- **Overlap**: existen observaciones comparables entre niveles de tratamiento en cada subgrupo.
- **Consistencia temporal**: las covariables usadas estaban disponibles al momento de originaciÃ³n.

En tÃ©rminos prÃ¡cticos: estos resultados son evidencia causal aplicada y Ãºtil para polÃ­tica, pero siempre deben leerse
como estimaciones sujetas a supuestos, no como â€œverdad absolutaâ€ independiente del diseÃ±o de datos.
"""
)

cate_df = load_parquet("cate_estimates")
segment_summary = load_parquet("causal_policy_segment_summary")
grade_summary = load_parquet("causal_policy_grade_summary")
rule_selected = load_parquet("causal_policy_rule_selected")
rule_candidates = load_parquet("causal_policy_rule_candidates")
simulation = load_parquet("causal_policy_simulation")

selected = rule_selected.iloc[0]

kpi_row(
    [
        {"label": "Regla elegida", "value": str(selected.get("rule_name", "N/D"))},
        {"label": "Action rate", "value": f"{selected.get('action_rate', 0) * 100:.1f}%"},
        {"label": "Valor neto total", "value": f"${selected.get('total_net_value', 0):,.0f}"},
        {"label": "ReducciÃ³n pÃ©rdida", "value": f"${selected.get('total_loss_reduction', 0):,.0f}"},
    ]
)

st.dataframe(
    pd.DataFrame(
        [
            {
                "MÃ©trica": "ATE/CATE",
                "Significado tÃ©cnico": "Efecto causal promedio/heterogÃ©neo de la tasa sobre default.",
                "Significado negocio": "Permite diseÃ±ar pricing diferenciado por sensibilidad real.",
            },
            {
                "MÃ©trica": "Action rate",
                "Significado tÃ©cnico": "ProporciÃ³n de clientes donde se recomienda intervenciÃ³n.",
                "Significado negocio": "TamaÃ±o operacional de la polÃ­tica causal.",
            },
            {
                "MÃ©trica": "Valor neto",
                "Significado tÃ©cnico": "PÃ©rdida evitada - costo de intervenciÃ³n en ingresos.",
                "Significado negocio": "Justifica econÃ³micamente la polÃ­tica seleccionada.",
            },
        ]
    ),
    use_container_width=True,
    hide_index=True,
)
st.markdown(
    """
En lenguaje de implementaciÃ³n, el pipeline causal produce una estimaciÃ³n por prÃ©stamo de sensibilidad (`cate`), luego
simula reglas operativas (quiÃ©n recibe intervenciÃ³n, de cuÃ¡nto, y con quÃ© impacto esperado en pÃ©rdidas/ingresos) y por
Ãºltimo selecciona la regla que maximiza valor neto bajo restricciones de cobertura y downside. Es decir, no se queda en
estimaciÃ³n de efecto: llega hasta polÃ­tica accionable.
"""
)

st.subheader("1) DistribuciÃ³n de efectos heterogÃ©neos (CATE)")
col1, col2 = st.columns(2)
with col1:
    fig = px.histogram(
        cate_df.sample(min(120000, len(cate_df)), random_state=21),
        x="cate",
        nbins=70,
        title="DistribuciÃ³n CATE",
        labels={"cate": "Efecto causal estimado de tasa sobre default"},
    )
    fig.update_layout(**PLOTLY_TEMPLATE["layout"], height=390)
    fig.update_traces(marker_color="#00D4AA")
    st.plotly_chart(fig, use_container_width=True)
    st.caption(
        "PropÃ³sito: observar heterogeneidad de sensibilidad causal. Insight: una distribuciÃ³n ancha de CATE confirma que "
        "una polÃ­tica Ãºnica de tasa no es Ã³ptima para todos los clientes."
    )

with col2:
    fig = px.box(
        cate_df.sample(min(120000, len(cate_df)), random_state=27),
        x="grade",
        y="cate",
        title="CATE por grade",
        labels={"grade": "Grade", "cate": "CATE"},
    )
    fig.update_layout(**PLOTLY_TEMPLATE["layout"], height=390)
    st.plotly_chart(fig, use_container_width=True)
    st.caption(
        "PropÃ³sito: comparar sensibilidad causal por grade. Insight: algunos segmentos concentran mayor potencial de reducciÃ³n "
        "de default ante ajuste de tasa."
    )

st.subheader("2) Impacto de polÃ­tica por segmento")
col3, col4 = st.columns(2)
with col3:
    fig = px.bar(
        segment_summary,
        x="segment",
        y="total_net_value",
        color="action_rate",
        title="Valor neto total por segmento",
        labels={"segment": "Segmento", "total_net_value": "Valor neto (USD)", "action_rate": "Action rate"},
        color_continuous_scale="Tealgrn",
    )
    fig.update_layout(**PLOTLY_TEMPLATE["layout"], height=390, coloraxis_showscale=False)
    st.plotly_chart(fig, use_container_width=True)
    st.caption(
        "PropÃ³sito: priorizar segmentos por valor econÃ³mico esperado. Insight: no siempre coincide el mayor valor con el mayor "
        "action rate, por lo que la regla debe optimizar ambos."
    )

with col4:
    fig = px.bar(
        grade_summary.sort_values("grade"),
        x="grade",
        y="action_rate",
        color="avg_pd_reduction",
        title="Action rate y reducciÃ³n de PD por grade",
        labels={"grade": "Grade", "action_rate": "Action rate", "avg_pd_reduction": "Î” PD"},
        color_continuous_scale="Sunsetdark",
    )
    fig.update_layout(**PLOTLY_TEMPLATE["layout"], height=390, coloraxis_showscale=False)
    fig.update_yaxes(tickformat=".0%")
    st.plotly_chart(fig, use_container_width=True)
    st.caption(
        "PropÃ³sito: medir intensidad de intervenciÃ³n por grade. Insight: action rate alto con baja mejora de PD puede no ser "
        "econÃ³micamente eficiente."
    )

st.markdown(
    """
Lectura conjunta de las grÃ¡ficas de esta secciÃ³n:
1. Histograma/boxplot de CATE: muestran heterogeneidad real de sensibilidad (base para personalizaciÃ³n de polÃ­tica).
2. Barras por segmento/grade: traducen esa heterogeneidad a valor econÃ³mico y factibilidad operativa.
3. Frontera de reglas: explicita el trade-off entre amplitud de intervenciÃ³n y retorno neto esperable.
4. Waterfall: deja auditable la composiciÃ³n de valor (pÃ©rdida evitada vs costo comercial).
"""
)
st.markdown(
    """
La lÃ³gica econÃ³mica detrÃ¡s de esta lectura es directa: primero identificamos dÃ³nde existe sensibilidad causal real,
luego traducimos esa sensibilidad a reglas accionables y, finalmente, medimos si el beneficio en pÃ©rdidas evitadas supera
el costo comercial de la intervenciÃ³n. Si ese Ãºltimo paso no cierra, la regla se descarta aunque el efecto causal sea alto.
"""
)

st.subheader("3) Frontera de reglas candidatas")
fig = px.scatter(
    rule_candidates,
    x="action_rate",
    y="total_net_value",
    color="pass_all",
    size="n_selected",
    text="rule_name",
    title="Trade-off entre cobertura de acciÃ³n y valor econÃ³mico",
    labels={"action_rate": "Action rate", "total_net_value": "Valor neto (USD)", "pass_all": "Cumple constraints"},
)
fig.update_traces(textposition="top center")
fig.update_layout(**PLOTLY_TEMPLATE["layout"], height=420)
st.plotly_chart(fig, use_container_width=True)
st.caption(
    "PropÃ³sito: evaluar frontera de reglas candidatas. Insight: la mejor regla no es la de mayor cobertura, sino la que "
    "maximiza valor cumpliendo restricciones."
)

st.dataframe(
    rule_candidates.sort_values(["pass_all", "total_net_value"], ascending=[False, False]),
    use_container_width=True,
    hide_index=True,
)

st.subheader("4) DescomposiciÃ³n econÃ³mica de la regla seleccionada")
fig = go.Figure(
    go.Waterfall(
        measure=["relative", "relative", "total"],
        x=["ReducciÃ³n de pÃ©rdida", "Impacto en ingresos", "Valor neto"],
        y=[
            selected.get("total_loss_reduction", 0),
            selected.get("total_revenue_impact", 0),
            selected.get("total_net_value", 0),
        ],
        connector={"line": {"color": "#A0AEC0"}},
    )
)
fig.update_layout(**PLOTLY_TEMPLATE["layout"], height=360, title="CÃ³mo se forma el valor causal neto")
st.plotly_chart(fig, use_container_width=True)
st.caption(
    "PropÃ³sito: descomponer creaciÃ³n de valor en ahorro de pÃ©rdida vs impacto comercial. Insight: hace auditable el trade-off "
    "de una polÃ­tica causal antes de implementarla."
)

st.markdown(
    """
**Mensaje metodolÃ³gico:**
- El modelo predictivo indica quiÃ©n tiene mÃ¡s riesgo.
- El bloque causal estima quÃ© palancas pueden cambiar ese riesgo.
- La optimizaciÃ³n convierte ese aprendizaje en reglas de portafolio econÃ³micamente coherentes.
"""
)
st.markdown(
    """
Como cierre, esta capa responde una pregunta estratÃ©gica del proyecto: â€œÂ¿quÃ© decisiones cambian realmente el riesgo y
con quÃ© costo-beneficio esperado?â€. La respuesta causal completa el stack porque evita confundir patrones observacionales
con decisiones efectivas. En tÃ©rminos narrativos, aquÃ­ pasamos de diagnosticar riesgo a diseÃ±ar intervenciÃ³n defendible.
"""
)
st.markdown(
    """
La implicaciÃ³n para negocio es fuerte: dos clientes con PD similar pueden requerir decisiones distintas si su sensibilidad
causal difiere. Por eso la capa causal no compite con el score, sino que agrega una dimensiÃ³n de polÃ­tica que permite
asignar acciones donde realmente producen valor neto, en lugar de aplicar reglas uniformes por conveniencia operativa.
"""
)

col_i, col_j = st.columns(2)
with col_i:
    img = get_notebook_image_path("07_causal_inference", "cell_020_out_01.png")
    if img.exists():
        st.image(
            str(img),
            caption="Notebook 07: correlaciÃ³n vs causalidad para efecto de tasa sobre default.",
            use_container_width=True,
        )
with col_j:
    img = get_notebook_image_path("07_causal_inference", "cell_026_out_01.png")
    if img.exists():
        st.image(
            str(img),
            caption="Notebook 07: sensibilidad de tasa y recomendaciÃ³n de polÃ­tica por segmento.",
            use_container_width=True,
        )

with st.expander("Muestra de simulaciÃ³n contrafactual por prÃ©stamo"):
    cols = [
        "id",
        "segment",
        "grade",
        "base_rate_pp",
        "recommended_delta_rate_pp",
        "expected_pd_reduction",
        "net_value",
        "recommended_action",
    ]
    st.dataframe(
        simulation[cols].sample(min(120, len(simulation)), random_state=3),
        use_container_width=True,
        hide_index=True,
    )

next_page_teaser(
    "Optimizador de Portafolio",
    "Integramos PD, incertidumbre y restricciones para decidir asignaciÃ³n de capital.",
    "pages/portfolio_optimizer.py",
)
